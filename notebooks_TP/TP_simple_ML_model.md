# Guide TP : Pipeline Machine Learning Complet (Iris Dataset)

Ce guide accompagne le notebook `TP_simple_ML_model.ipynb`. Votre objectif est de construire un pipeline de Machine Learning complet pour classifier les fleurs d'Iris, puis de structurer votre code proprement.

## Objectifs P√©dagogiques
- Charger et explorer un dataset classique (Iris).
- Cr√©er et entra√Æner un pipeline scikit-learn (Preprocessing + Mod√®le).
- **Refactoring** : Sortir du notebook pour cr√©er un script Python modulaire.

---

## √âtape 1 : Chargement et Exploration des Donn√©es

**T√¢che** : Compl√©tez la fonction `create_train_test_split` dans le notebook. Utilisez `train_test_split` de scikit-learn.

---

## √âtape 2 : Pr√©-traitement des Donn√©es (Preprocessing)

**T√¢che** : Compl√©tez la fonction `create_preprocessing_pipeline` pour retourner un `StandardScaler`.

**Question** : Le `StandardScaler` transforme les donn√©es pour qu'elles aient une moyenne de 0 et un √©cart-type de 1. Pourquoi est-ce important pour certains algorithmes de Machine Learning d'avoir des donn√©es √† la m√™me √©chelle ?

---

## √âtape 3 : Cr√©ation du Pipeline Mod√®le

**T√¢che** : Compl√©tez `create_model_pipeline` pour assembler le scaler et le classifieur `RandomForestClassifier`.

**Question** : Quel est l'avantage d'utiliser un objet `Pipeline` de scikit-learn plut√¥t que d'appliquer manuellement le scaler puis le mod√®le ? (Indice : pensez √† ce qui se passe lors de la pr√©diction sur de nouvelles donn√©es).
**Question** :  Comment est-ce que cette pipeline est utile √† avoir si on va d√©velopper une API avec ce mod√®le ?
---

## √âtape 4 : √âvaluation du Mod√®le

**T√¢che** : Compl√©tez `evaluate_model` pour calculer la matrice de confusion, l'accuracy, la pr√©cision, le rappel (recall) et le F1-score.

---

## √âtape 5 : Ex√©cution Compl√®te

**T√¢che** : Compl√©tez la fonction `main` pour orchestrer toutes les √©tapes pr√©c√©dentes. Ex√©cutez le notebook et observez les graphiques r√©sultats.

---

## üöÄ √âtape Finale : "Clean Code" & Refactoring

Les notebooks sont excellents pour l'exp√©rimentation, mais pour mettre un mod√®le en production ou travailler en √©quipe, nous utilisons des scripts Python `.py`.

**Votre mission :**

1.  Cr√©ez un nouveau fichier nomm√© `model_pipeline.py` dans le dossier `src/` de votre projet.
2.  Copiez toutes les fonctions d√©finies dans votre notebook (`load_and_explore_data`, `create_train_test_split`, `create_preprocessing_pipeline`, etc.) dans ce fichier.
3.  N'oubliez pas de copier √©galement les **imports** n√©cessaires en haut du fichier.
4.  √Ä la fin du fichier `src/model_pipeline.py`, ajoutez le bloc suivant pour permettre l'ex√©cution du script :

```python
if __name__ == "__main__":
    # Vous pouvez appeler votre fonction main() ici ou simplement tester une ex√©cution
    print("Ex√©cution du pipeline depuis le script...")
    trained_model = main()
```

5.  **V√©rification** :
    *   Ouvrez un terminal dans VS Code.
    *   Placez-vous √† la racine du projet.
    *  Activer votre vitual environmenet en faisant `source .venv/bin/activate` ou autre en fonction de votre gestionnaire d'environnement (e.g: conda activate <myenv>).
    *   Ex√©cutez votre script avec la commande :
        ```bash
        python src/model_pipeline.py
        ```
        ou  avec `uv run src/model_pipeline.py`

Si tout fonctionne, vous verrez vos logs s'afficher dans le terminal (et les graphiques s'ouvriront ou seront sauvegard√©s si configur√©). F√©licitations, vous avez transform√© votre exp√©rimentation en code logiciel "robuste" !
